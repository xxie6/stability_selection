---
title: "sparse_overlap_setting"
author: "Annie Xie"
date: "2025-09-11"
output: 
  workflowr::wflow_html:
    code_folding: hide
editor_options:
  chunk_output_type: console
---

# Introduction
In this analysis, we are interested in testing stability selection approaches in the sparse, overlapping setting.

At a high level, the stability selection involves 1) splitting the data into two subsets, 2) applying the method to each subset, 3) choosing the components that have high correspondence across the two sets of results. We will test two different approaches to step 1). The first approach is splitting the data by splitting the columns. This approach feels intuitive since we are interested in the loadings matrix, which says something about the samples in the dataset. In a population genetics application, one could argue that all of the chromosomes are undergoing evolution independently, and so you could split the data by even vs. odd chromosomes to get two different datasets. However, in a single-cell RNA-seq application, it feels more natural to split the data by cells -- this feels more like creating sub-datasets compared to splitting by genes (unless you want to make some assumption that the genes are pulled from a "population", but I think that feels less natural). This motivates the second approach: splitting the data by splitting the rows.

I imagine that splitting the columns will be better than splitting the rows in this setting because each sample is only active in a couple of factors. Therefore, splitting by samples may lead some factors to have weaker signal and thus be harder to find.

```{r, message = FALSE, warning = FALSE}
library(dplyr)
library(ggplot2)
library(pheatmap)
```

```{r}
source('code/visualization_functions.R')
source('code/stability_selection_functions.R')
```

```{r}
permute_L <- function(est, truth){
  K_est <- ncol(est)
  K_truth <- ncol(truth)
  n <- nrow(est)

  #if estimates don't have same number of columns, try padding the estimate with zeros and make cosine similarity zero
  if (K_est < K_truth){
    est <- cbind(est, matrix(rep(0, n*(K_truth-K_est)), nrow = n))
  }

  if (K_est > K_truth){
    truth <- cbind(truth, matrix(rep(0, n*(K_est - K_truth)), nrow = n))
  }

  #normalize est and truth
  norms_est <- apply(est, 2, function(x){sqrt(sum(x^2))})
  norms_est[norms_est == 0] <- Inf

  norms_truth <- apply(truth, 2, function(x){sqrt(sum(x^2))})
  norms_truth[norms_truth == 0] <- Inf

  est_normalized <- t(t(est)/norms_est)
  truth_normalized <- t(t(truth)/norms_truth)

  #compute matrix of cosine similarities
  cosine_sim_matrix <- abs(crossprod(est_normalized, truth_normalized))
  assignment_problem <- lpSolve::lp.assign(t(cosine_sim_matrix), direction = "max")

  perm <- apply(assignment_problem$solution, 1, which.max)
  return(est[,perm])
}
```

# Data Generation

In this analysis, we will focus on the sparse overlapping setting.
```{r}
sim_binary_loadings_data <- function(args) {
  set.seed(args$seed)
  
  FF <- matrix(rnorm(args$k * args$p, sd = args$group_sd), ncol = args$k)
  if (args$constrain_F) {
    FF_svd <- svd(FF)
    FF <- FF_svd$u
    FF <- t(t(FF) * rep(args$group_sd, args$k) * sqrt(p))
  }
  LL <- matrix(rbinom(args$n*args$k, 1, args$pi1), nrow = args$n, ncol = args$k)
  E <- matrix(rnorm(args$n * args$p, sd = args$indiv_sd), nrow = args$n)
  
  Y <- LL %*% t(FF) + E
  YYt <- (1/args$p)*tcrossprod(Y)
  
  return(list(Y = Y, YYt = YYt, LL = LL, FF = FF, K = ncol(LL)))
}
```

```{r}
n <- 100
p <- 1000
k <- 10
pi1 <- 0.1
indiv_sd <- 1
group_sd <- 1
seed <- 1
sim_args = list(n = n, p = p, k = k, pi1 = pi1, indiv_sd = indiv_sd, group_sd = group_sd, seed = seed, constrain_F = FALSE)
sim_data <- sim_binary_loadings_data(sim_args)
```

This is a heatmap of the true loadings matrix:
```{r}
plot_heatmap(sim_data$LL)
```

# GBCD
In this section, I try stability selection with the GBCD method. In my experiments, I've found that GBCD tends to return extra factors (partially because the point-Laplace initialization will yield extra factors).

## Stability Selection via Splitting Columns

First, I try splitting the data by splitting the columns.
```{r}
set.seed(1)
X_split_by_col <- stability_selection_split_data(sim_data$Y, dim = 'columns')
```

```{r}
gbcd_fits_by_col <- list()
for (i in 1:(length(X_split_by_col)-2)){
  gbcd_fits_by_col[[i]] <- gbcd::fit_gbcd(X_split_by_col[[i]], 
                                   Kmax = 10, 
                                   prior = ebnm::ebnm_generalized_binary,
                                   verbose = 0)$L
}
```

This is heatmap of the loadings estimate from the first subset:
```{r}
L1_permuted <- permute_L(gbcd_fits_by_col[[1]], sim_data$LL)
plot_heatmap(L1_permuted, colors_range = c('blue','gray96','red'), brks = seq(-max(abs(L1_permuted)), max(abs(L1_permuted)), length.out = 50))
```

This is a heatmap of the loadings estimate from the second subset:
```{r}
L2_permuted <- permute_L(gbcd_fits_by_col[[2]], sim_data$LL)
plot_heatmap(L2_permuted, colors_range = c('blue','gray96','red'), brks = seq(-max(abs(L2_permuted)), max(abs(L2_permuted)), length.out = 50))
```

```{r}
results_by_col <- stability_selection_post_processing(gbcd_fits_by_col[[1]], gbcd_fits_by_col[[2]], threshold = 0.8)
L_est_by_col <- results_by_col$L
```

This is a heatmap of the final loadings estimate:
```{r}
L_est_by_col_permuted <- permute_L(L_est_by_col, sim_data$LL)
L_est_by_col_permuted <- L_est_by_col_permuted[, apply(L_est_by_col_permuted, 2, function(x){sum(x^2)}) > 10^(-10)]
plot_heatmap(L_est_by_col_permuted, colors_range = c('blue','gray96','red'), brks = seq(-max(abs(L_est_by_col_permuted)), max(abs(L_est_by_col_permuted)), length.out = 50))
```

This is the correlation between the estimate and the true loadings matrix
```{r}
diag(cor(L_est_by_col_permuted, sim_data$LL))
```

With a threshold of 0.8, the method recovered nine of the ten components. However, two of the components do not exactly match the true components. We did get rid of most of the noise.

## Stability Selection via Splitting Rows

Now, we try splitting the rows:
```{r}
set.seed(1)
X_split_by_row <- stability_selection_split_data(sim_data$Y, dim = 'rows')
```

```{r}
gbcd_fits_by_row_F <- list()
gbcd_fits_by_row_L <- list()
for (i in 1:(length(X_split_by_row)-2)){
  gbcd_fit <- gbcd::fit_gbcd(X_split_by_row[[i]], 
                                   Kmax = 4, 
                                   prior = ebnm::ebnm_generalized_binary,
                                   verbose = 0)
  gbcd_fits_by_row_F[[i]] <- gbcd_fit$F$lfc
  gbcd_fits_by_row_L[[i]] <- gbcd_fit$L
}
```

This is heatmap of the loadings estimate from the first subset:
```{r}
plot_heatmap(gbcd_fits_by_row_L[[1]][order(X_split_by_row[[3]]),], colors_range = c('blue','gray96','red'), brks = seq(-max(abs(gbcd_fits_by_row_L[[1]])), max(abs(gbcd_fits_by_row_L[[1]])), length.out = 50))
```

This is heatmap of the loadings estimate from the second subset:
```{r}
plot_heatmap(gbcd_fits_by_row_L[[2]], colors_range = c('blue','gray96','red'), brks = seq(-max(abs(gbcd_fits_by_row_L[[2]])), max(abs(gbcd_fits_by_row_L[[2]])), length.out = 50))
```

```{r}
results_by_row <- stability_selection_row_split_post_processing(gbcd_fits_by_row_L[[1]], gbcd_fits_by_row_L[[2]], gbcd_fits_by_row_F[[1]], gbcd_fits_by_row_F[[2]], threshold = 0.5)
L_est_by_row <- results_by_row$L
L_est_by_row <- L_est_by_row[order(c(X_split_by_row[[3]], X_split_by_row[[4]])), ]
```

This is a heatmap of the final loadings estimate:
```{r}
L_est_by_row_permuted <- permute_L(L_est_by_row, sim_data$LL)
L_est_by_row_permuted <- L_est_by_row_permuted[, apply(L_est_by_row_permuted, 2, function(x){sum(x^2)}) > 10^(-10)]
plot_heatmap(L_est_by_row_permuted, colors_range = c('blue','gray96','red'), brks = seq(-max(abs(L_est_by_row_permuted)), max(abs(L_est_by_row_permuted)), length.out = 50))
```

This is the correlation between the estimate and the true loadings matrix:
```{r}
apply(cor(L_est_by_row_permuted, sim_data$LL), 1, max)
```

With a threshold of 0.5, the method recovered four of the ten factors. However, some of the factors do not exactly match the true factors.

# EBCD

In this section, I try stability selection with the GBCD method. When given a `Kmax` value that is larger than the true number of components, I've found that EBCD usually returns extra factors. So in this section, when I run EBCD, I give the method double the true number of components.

## Stability Selection via Splitting Columns

```{r}
set.seed(1)
ebcd_fits_by_col <- list()
for (i in 1:(length(X_split_by_col)-2)){
  ebcd_fits_by_col[[i]] <- ebcd::ebcd(t(X_split_by_col[[i]]), 
                                   Kmax = 20, 
                                   ebnm_fn = ebnm::ebnm_generalized_binary)$EL
}
```

This is heatmap of the loadings estimate from the first subset:
```{r}
plot_heatmap(ebcd_fits_by_col[[1]][order(X_split_by_row[[3]]),], colors_range = c('blue','gray96','red'), brks = seq(-max(abs(ebcd_fits_by_col[[1]])), max(abs(ebcd_fits_by_col[[1]])), length.out = 50))
```

This is a heatmap of the loadings estimate from the second subset:
```{r}
plot_heatmap(ebcd_fits_by_col[[2]], colors_range = c('blue','gray96','red'), brks = seq(-max(abs(ebcd_fits_by_col[[2]])), max(abs(ebcd_fits_by_col[[2]])), length.out = 50))
```

```{r}
results_by_col <- stability_selection_post_processing(ebcd_fits_by_col[[1]], ebcd_fits_by_col[[2]], threshold = 0.5)
L_est_by_col <- results_by_col$L
```

This is a heatmap of the final loadings estimate:
```{r}
L_est_by_col_permuted <- permute_L(L_est_by_col, sim_data$LL)
L_est_by_col_permuted <- L_est_by_col_permuted[, apply(L_est_by_col_permuted, 2, function(x){sum(x^2)}) > 10^(-10)]
plot_heatmap(L_est_by_col_permuted, colors_range = c('blue','gray96','red'), brks = seq(-max(abs(L_est_by_col_permuted)), max(abs(L_est_by_col_permuted)), length.out = 50))
```

These are the correlations between the estimates and the true factors (which are paired to maximize crossproduct similarity):
```{r}
diag(cor(L_est_by_col_permuted, sim_data$LL))
```

The method recovers all ten components nearly perfectly.

## Stability Selection via Splitting Rows

```{r}
transform_ebcd_Z <- function(Y, ebcd_obj){
  Y.svd <- svd(Y)
  Y.UV <- Y.svd$u %*% t(Y.svd$v)
  Z_transformed <- Y.UV %*% ebcd_obj$Z
  return(Z_transformed)
}
```

```{r}
set.seed(1)
ebcd_fits_by_row_L <- list()
ebcd_fits_by_row_F <- list()
for (i in 1:(length(X_split_by_row)-2)){
  ebcd_fit <- ebcd::ebcd(t(X_split_by_row[[i]]), 
                                   Kmax = 20, 
                                   ebnm_fn = ebnm::ebnm_generalized_binary)
  ebcd_fits_by_row_L[[i]] <- ebcd_fit$EL
  ebcd_fits_by_row_F[[i]] <- transform_ebcd_Z(t(X_split_by_row[[i]]), ebcd_fit)
}
```

This is a heatmap of the loadings estimate from the first subset:
```{r}
plot_heatmap(ebcd_fits_by_row_L[[1]][order(X_split_by_row[[3]]),], colors_range = c('blue','gray96','red'), brks = seq(-max(abs(ebcd_fits_by_row_L[[1]])), max(abs(ebcd_fits_by_row_L[[1]])), length.out = 50))
```

This is a heatmap of the loadings estimate from the second subset:
```{r}
plot_heatmap(ebcd_fits_by_row_L[[2]], colors_range = c('blue','gray96','red'), brks = seq(-max(abs(ebcd_fits_by_row_L[[2]])), max(abs(ebcd_fits_by_row_L[[2]])), length.out = 50))
```

```{r}
results_by_row <- stability_selection_row_split_post_processing(ebcd_fits_by_row_L[[1]], ebcd_fits_by_row_L[[2]], ebcd_fits_by_row_F[[1]], ebcd_fits_by_row_F[[2]], threshold = 0.5)
L_est_by_row <- results_by_row$L
L_est_by_row <- L_est_by_row[order(c(X_split_by_row[[3]], X_split_by_row[[4]])), ]
```

This is a heatmap of the final loadings estimate:
```{r}
L_est_by_row_permuted <- permute_L(L_est_by_row, sim_data$LL)
L_est_by_row_permuted <- L_est_by_row_permuted[, apply(L_est_by_row_permuted, 2, function(x){sum(x^2)}) > 10^(-10)]
plot_heatmap(L_est_by_row_permuted, colors_range = c('blue','gray96','red'), brks = seq(-max(abs(L_est_by_row_permuted)), max(abs(L_est_by_row_permuted)), length.out = 50))
```

This is the correlation between the estimate and the true loadings matrix:
```{r}
apply(cor(L_est_by_row_permuted, sim_data$LL), 1, max)
```

With a threshold of 0.5, the method returns seven components. However, two of the components do not exactly match the true components.

# CoDesymNMF

In this section, I try stability selection with the CoDesymNMF method. Similar to EBCD, when given a `Kmax` value that is larger than the true number of components, the method usually returns extra factors. Note that in this section, when I run CoDesymNMF, I give the method double the true number of components.

## Stability Selection via Splitting Columns

```{r}
codesymnmf_fits_by_col <- list()
for (i in 1:(length(X_split_by_col) - 2)){
  cov_mat <- tcrossprod(X_split_by_col[[i]])/ncol(X_split_by_col[[i]])
  codesymnmf_fits_by_col[[i]] <- codesymnmf::codesymnmf(cov_mat, 20)$H
}
```

This is heatmap of the loadings estimate from the first subset:
```{r}
L1_permuted <- permute_L(codesymnmf_fits_by_col[[1]], sim_data$LL)
plot_heatmap(L1_permuted, colors_range = c('blue','gray96','red'), brks = seq(-max(abs(L1_permuted)), max(abs(L1_permuted)), length.out = 50))
```

This is a heatmap of the loadings estimate from the second subset:
```{r}
L2_permuted <- permute_L(codesymnmf_fits_by_col[[2]], sim_data$LL)
plot_heatmap(L2_permuted, colors_range = c('blue','gray96','red'), brks = seq(-max(abs(L2_permuted)), max(abs(L2_permuted)), length.out = 50))
```

```{r}
results_by_col <- stability_selection_post_processing(codesymnmf_fits_by_col[[1]], codesymnmf_fits_by_col[[2]], threshold = 0.8)
L_est_by_col <- results_by_col$L
```

This is a heatmap of the final loadings estimate:
```{r}
L_est_by_col_permuted <- permute_L(L_est_by_col, sim_data$LL)
L_est_by_col_permuted <- L_est_by_col_permuted[, apply(L_est_by_col_permuted, 2, function(x){sum(x^2)}) > 10^(-10)]
plot_heatmap(L_est_by_col_permuted, colors_range = c('blue','gray96','red'), brks = seq(-max(abs(L_est_by_col_permuted)), max(abs(L_est_by_col_permuted)), length.out = 50))
```

This is the correlation between the estimate and the true loadings matrix:
```{r}
apply(cor(L_est_by_col_permuted, sim_data$LL), 1, max)
```

The method returns 13 factors in this case. Some of the factors look like they may be capturing similar effects to other factors, e.g. factor 12 looks a bit like factor 10. Similarly, factor 11 looks like factor 9.

## Stability Selection via Splitting Rows

```{r}
PolarU <- function(A) {
  svdA <- svd(A)
  out <- svdA$u %*% t(svdA$v)
  return(out)
}
```

```{r}
codesymnmf_fits_by_row_L <- list()
codesymnmf_fits_by_row_F <- list()
for (i in 1:(length(X_split_by_row)-2)){
  cov_mat <- tcrossprod(X_split_by_row[[i]])/ncol(X_split_by_row[[i]])
  codesymnmf_fits_by_row_L[[i]] <- codesymnmf::codesymnmf(cov_mat, 8)$H
  codesymnmf_fits_by_row_F[[i]] <- PolarU(t(X_split_by_row[[i]]) %*% codesymnmf_fits_by_row_L[[i]])
}
```

This is heatmap of the loadings estimate from the first subset:
```{r}
plot_heatmap(codesymnmf_fits_by_row_L[[1]][order(X_split_by_row[[3]]),], colors_range = c('blue','gray96','red'), brks = seq(-max(abs(codesymnmf_fits_by_row_L[[1]])), max(abs(codesymnmf_fits_by_row_L[[1]])), length.out = 50))
```

This is heatmap of the loadings estimate from the second subset:
```{r}
plot_heatmap(codesymnmf_fits_by_row_L[[2]][order(X_split_by_row[[3]]),], colors_range = c('blue','gray96','red'), brks = seq(-max(abs(codesymnmf_fits_by_row_L[[2]])), max(abs(codesymnmf_fits_by_row_L[[2]])), length.out = 50))
```

```{r}
results_by_row <- stability_selection_row_split_post_processing(codesymnmf_fits_by_row_L[[1]], codesymnmf_fits_by_row_L[[2]], codesymnmf_fits_by_row_F[[1]], codesymnmf_fits_by_row_F[[2]], threshold = 0.6)
L_est_by_row <- results_by_row$L
L_est_by_row <- L_est_by_row[order(c(X_split_by_row[[3]], X_split_by_row[[4]])), , drop = FALSE]
```

This is a heatmap of the final loadings estimate with a reduced threshold:
```{r}
L_est_by_row_permuted <- permute_L(L_est_by_row, sim_data$LL)
L_est_by_row_permuted <- L_est_by_row_permuted[, apply(L_est_by_row_permuted, 2, function(x){sum(x^2)}) > 10^(-10)]
plot_heatmap(L_est_by_row_permuted, colors_range = c('blue','gray96','red'), brks = seq(-max(abs(L_est_by_row_permuted)), max(abs(L_est_by_row_permuted)), length.out = 50))
```

This is the correlation between the estimate and the true loadings matrix:
```{r}
apply(cor(L_est_by_row_permuted, sim_data$LL), 1, max)
```

With a threshold of 0.6, the method returns four out of the ten factors.

# EBMFcov

In this section, I try stability selection with the EBMFcov method. In my experiments, I've found that when given a larger `Kmax`, EBMFcov will get around the correct number of factors, and then it will add essentially trivial factors. I wonder if the stability selection procedure will help get rid of these extra factors. The hope is that it can. However, if both estimates have factors that look like this, then maybe these factors will still get returned. Note that in this section, when I run EBMFcov, I give the method double the true number of components.

```{r}
cov_fit <- function(covmat, ebnm_fn = ebnm::ebnm_point_laplace, Kmax = 1000, verbose.lvl = 0, backfit = TRUE) {
  fl <- flash_init(covmat, var_type = 0) %>%
    flash_set_verbose(verbose.lvl) %>%
    flash_greedy(ebnm_fn = ebnm_fn, Kmax = Kmax)
  if (backfit == TRUE){
    fl <- flash_backfit(fl)
  }
  s2 <- max(0, mean(diag(covmat) - diag(fitted(fl))))
  s2_diff <- Inf
  while(s2 > 0 && abs(s2_diff - 1) > 1e-4) {
    covmat_minuss2 <- covmat - diag(rep(s2, ncol(covmat)))
    fl <- flash_init(covmat_minuss2, var_type = 0) %>%
      flash_set_verbose(verbose.lvl) %>%
      flash_greedy(ebnm_fn = ebnm_fn, Kmax = Kmax)
    if (backfit == TRUE){
      fl <- flash_backfit(fl)
    }
    old_s2 <- s2
    s2 <- max(0, mean(diag(covmat) - diag(fitted(fl))))
    s2_diff <- s2 / old_s2
  }
  
  return(list(fl=fl, s2 = s2))
}
```

## Stability Selection via Splitting Columns

```{r}
library(flashier)
```

```{r}
ebmfcov_fits_by_col <- list()
for (i in 1:(length(X_split_by_col) - 2)){
  cov_mat <- tcrossprod(X_split_by_col[[i]])/ncol(X_split_by_col[[i]])
  fl <- cov_fit(cov_mat, ebnm_fn = ebnm::ebnm_generalized_binary, Kmax = 20)$fl
  fl_scaled <- ldf(fl)
  L_scaled <- fl_scaled$L %*% diag(sqrt(fl_scaled$D))
  ebmfcov_fits_by_col[[i]] <- L_scaled
}
```

Just a note: this took a really long time to run. I didn't expect it to take so long.

This is heatmap of the loadings estimate from the first subset:
```{r}
L1_permuted <- permute_L(ebmfcov_fits_by_col[[1]], sim_data$LL)
plot_heatmap(L1_permuted, colors_range = c('blue','gray96','red'), brks = seq(-max(abs(L1_permuted)), max(abs(L1_permuted)), length.out = 50))
```

These are plots of the factors which appear to be trivial:
```{r}
par(mfrow = c(6, 2), mar = c(2, 2, 2, 2))
for (i in c(3, 11:20)){
  plot(L1_permuted[,i])
}
par(mfrow = c(1, 1))
```

This is a heatmap of the loadings estimate from the second subset:
```{r}
L2_permuted <- permute_L(ebmfcov_fits_by_col[[2]], sim_data$LL)
plot_heatmap(L2_permuted, colors_range = c('blue','gray96','red'), brks = seq(-max(abs(L2_permuted)), max(abs(L2_permuted)), length.out = 50))
```

These are plots of the factors which appear to be trivial:
```{r}
par(mfrow = c(5, 2), mar = c(2, 2, 2, 2))
for (i in c(11:18, 20)){
  plot(L2_permuted[,i])
}
par(mfrow = c(1, 1))
```

```{r}
results_by_col <- stability_selection_post_processing(ebmfcov_fits_by_col[[1]], ebmfcov_fits_by_col[[2]], threshold = 0.99)
L_est_by_col <- results_by_col$L
```

This is a heatmap of the final loadings estimate:
```{r}
L_est_by_col_permuted <- permute_L(L_est_by_col, sim_data$LL)
L_est_by_col_permuted <- L_est_by_col_permuted[, apply(L_est_by_col_permuted, 2, function(x){sum(x^2)}) > 10^(-10)]
plot_heatmap(L_est_by_col_permuted, colors_range = c('blue','gray96','red'), brks = seq(-max(abs(L_est_by_col_permuted)), max(abs(L_est_by_col_permuted)), length.out = 50))
```

This is a heatmap of the factors in the final loadings estimate that appear to be trivial:
```{r}
plot_heatmap(L_est_by_col_permuted[, c(3, 6, 11:19)], colors_range = c('blue','gray96','red'), brks = seq(-max(abs(L_est_by_col_permuted[, c(3, 6, 11:19)])), max(abs(L_est_by_col_permuted[, c(3, 6, 11:19)])), length.out = 50))
```

This is the correlation between the estimate and the true loadings matrix:
```{r}
apply(cor(L_est_by_col_permuted, sim_data$LL), 1, max)
```

The final loadings estimate has 19 factors. However, many of them appear to be near zero.

This is the correlation between the trivial factors in the first estimate and the trivial factors in the second estimate:
```{r}
cor(L1_permuted[,c(3, 11:20)], L2_permuted[,c(11:18,20)])
```

For comparison, this is the cosine similarity matrix of the trivial factors:
```{r}
compute_cosine_sim_matrix(L1_permuted[,c(3, 11:20)], L2_permuted[,c(11:18,20)])
```

This is a plot of one of the trivial factors from the first estimate and one of the trivial factors from the second estimate:
```{r}
plot(x = L1_permuted[,11], L2_permuted[,11])
```

This suggests that looking at the correlation and the cosine similarity leads to different results. When looking at cosine similarity, these trivial factors are kept. But if we were looking at correlation, they would not be kept. Maybe I should try centering the data and looking at the cosine similarity (which I have defined for zero vectors)? This is something for me to keep in mind.

## Stability Selection via Splitting Rows

```{r}
ebmfcov_fits_by_row_L <- list()
ebmfcov_fits_by_row_F <- list()
for (i in 1:(length(X_split_by_row)-2)){
  cov_mat <- tcrossprod(X_split_by_row[[i]])/ncol(X_split_by_row[[i]])
  fl <- cov_fit(cov_mat, ebnm_fn = ebnm::ebnm_generalized_binary, Kmax = 20)$fl
  fl_scaled <- ldf(fl)
  L_scaled <- fl_scaled$L %*% diag(sqrt(fl_scaled$D))
  ebmfcov_fits_by_row_L[[i]] <- L_scaled
  ebmfcov_fits_by_row_F[[i]] <- PolarU(t(X_split_by_row[[i]]) %*% ebmfcov_fits_by_row_L[[i]])
}
```

This is heatmap of the loadings estimate from the first subset:
```{r}
plot_heatmap(ebmfcov_fits_by_row_L[[1]][order(X_split_by_row[[3]]),], colors_range = c('blue','gray96','red'), brks = seq(-max(abs(ebmfcov_fits_by_row_L[[1]])), max(abs(ebmfcov_fits_by_row_L[[1]])), length.out = 50))
```

This is heatmap of the loadings estimate from the second subset:
```{r}
plot_heatmap(ebmfcov_fits_by_row_L[[2]], colors_range = c('blue','gray96','red'), brks = seq(-max(abs(ebmfcov_fits_by_row_L[[2]])), max(abs(ebmfcov_fits_by_row_L[[2]])), length.out = 50))
```

```{r}
results_by_row <- stability_selection_row_split_post_processing(ebmfcov_fits_by_row_L[[1]], ebmfcov_fits_by_row_L[[2]], ebmfcov_fits_by_row_F[[1]], ebmfcov_fits_by_row_F[[2]], threshold = 0.5)
L_est_by_row <- results_by_row$L
L_est_by_row <- L_est_by_row[order(c(X_split_by_row[[3]], X_split_by_row[[4]])), , drop = FALSE]
```

This is a heatmap of the final loadings estimate:
```{r}
L_est_by_row_permuted <- permute_L(L_est_by_row, sim_data$LL)
L_est_by_row_permuted <- L_est_by_row_permuted[, apply(L_est_by_row_permuted, 2, function(x){sum(x^2)}) > 10^(-10)]
plot_heatmap(L_est_by_row_permuted, colors_range = c('blue','gray96','red'), brks = seq(-max(abs(L_est_by_row_permuted)), max(abs(L_est_by_row_permuted)), length.out = 50))
```

This is the correlation of the estimate and true loadings matrix:
```{r}
apply(cor(L_est_by_row_permuted, sim_data$LL), 1, max)
```

With a threshold of 0.5, the method returns seven factors.

# Observations
As expected, this setting is the hardest of the four settings. The only method that was able to recover all ten components accurately is EBCD with the column-split stability selection.
